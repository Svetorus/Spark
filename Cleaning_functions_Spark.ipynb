{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Документация Spark  \n",
    "https://spark.apache.org/docs/2.4.0/api/python/pyspark.sql.html#pyspark.sql.functions.regexp_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col,length,split, udf, initcap, regexp_extract, to_date, date_format,date_add,lower\n",
    "from sys import argv\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import HiveContext, SQLContext, SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from #### import vertica\n",
    "from #### import get_spark_session\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выводим номерацию колонок \n",
    "\n",
    "def numering(df):\n",
    "    n = 0\n",
    "    for i in df.columns:\n",
    "        if n < len(df.columns):\n",
    "            print(f' сol_{n}'+' : '+f'{i}')\n",
    "        n = n+1\n",
    "numering(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удобства назначаем колонки номерами\n",
    "\n",
    "col_0 = df_spark.columns[0]\n",
    "col_1 = df_spark.columns[1]\n",
    "col_2 = df_spark.columns[2]\n",
    "col_3 = df_spark.columns[3]\n",
    "col_4 = df_spark.columns[4]\n",
    "col_5 = df_spark.columns[5]\n",
    "col_6 = df_spark.columns[6]\n",
    "col_7 = df_spark.columns[7]\n",
    "col_8 = df_spark.columns[8]\n",
    "col_9 = df_spark.columns[9]\n",
    "col_10 = df_spark.columns[10]\n",
    "col_11 = df_spark.columns[11]\n",
    "col_12 = df_spark.columns[12]\n",
    "col_13 = df_spark.columns[13]\n",
    "col_14 = df_spark.columns[14]\n",
    "col_15 = df_spark.columns[15]\n",
    "col_16 = df_spark.columns[16]\n",
    "# col_17 = df_spark.columns[17]\n",
    "# col_18 = df_spark.columns[18]\n",
    "# col_19 = df_spark.columns[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ФУНКЦИИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для <font color=\"green\">ВСЕХ</font> колонок во Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для ВСЕХ колонок во Frame\n",
    "# функция для проверки данных\n",
    "\n",
    "def looking_for_anomalies_in_columns(df):\n",
    "    n = 0\n",
    "    for i in df.columns:\n",
    "        if n < len(df.columns):\n",
    "            print(f\"Колонка: {df.columns[n]}\")\n",
    "            print(f' ')\n",
    "            print(f'Кол-во значений: {df.select(df.columns[n]).count()}')\n",
    "            print(f'Кол-во уникальных значений: {df.select(df.columns[n]).distinct().count()}')\n",
    "            print(f'Кол-во значений NaN: {df.select(df.columns[n]).filter(col(df.columns[n]).rlike(\"^[nan]*$|^[Nan]*$|^[null]*$\")).count()}')\n",
    "            print(f'Кол-во значений ^ пробелы: {df.select(df.columns[n]).filter(col(df.columns[n]).rlike(\"^ \")).count()}')\n",
    "            print(f'Кол-во значений уникальных ^ пробелы: {df.select(df.columns[n]).filter(col(df.columns[n]).rlike(\"^ \")).distinct().count()}')\n",
    "            print(f'Кол-во значений пробелы $: {df.select(df.columns[n]).filter(col(df.columns[n]).rlike(\" $\")).count()}')\n",
    "            print(f'Кол-во значений уникальных $ пробелы: {df.select(df.columns[n]).filter(col(df.columns[n]).rlike(\" $\")).distinct().count()}')\n",
    "            print(f'Странный пробел который не пробел(читается регуляркой как буква) : {df.select(df.columns[n]).filter(col(df.columns[n]).rlike(\" \")).count()}')\n",
    "            print(f' ')\n",
    "        n = n+1   \n",
    "        \n",
    "looking_for_anomalies_in_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для <font color=\"blue\">ОДНОЙ</font> колонки во Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для просмотра ОДНОЙ колонки\n",
    "# функция для проверки данных\n",
    "\n",
    "def looking_for_anomalies(df,column): \n",
    "    print(f'Кол-во значений: {df.select(column).count()}')\n",
    "    print(f'Кол-во уникальных значений: {df.select(column).distinct().count()}')\n",
    "    print(f'Кол-во значений NaN: {df.select(column).filter(col(column).rlike(\"^[nan]*$|^[Nan]*$|^[null]*$\")).count()}')\n",
    "    print(f'Кол-во значений с цифрами: {df.select(column).filter(col(column).rlike(\"[0-9]+\")).count()}')\n",
    "    print(f'Кол-во значений в начале пробелы: {df.select(column).filter(col(column).rlike(\"^ \")).count()}')\n",
    "    print(f'Кол-во значений уникальных в начале пробелы: {df.select(column).filter(col(column).rlike(\"^ \")).distinct().count()}')\n",
    "    print(f'Кол-во значений пробелы в конце: {df.select(column).filter(col(column).rlike(\" $\")).count()}')\n",
    "    print(f'Кол-во значений уникальных в конце пробелы : {df.select(column).filter(col(column).rlike(\" $\")).distinct().count()}')\n",
    "    print(f'Странный пробел который не пробел(читается регуляркой как буква) : {df.select(column).filter(col(column).rlike(\" \")).count()}')\n",
    "    print(f'Кол-во значений UNKNOWN: {df.select(column).filter(col(column).rlike(\"UNKNOWN\")).count()}')\n",
    "    \n",
    "looking_for_anomalies(df,'col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для проверки данных на наличие букв и цифр\n",
    "\n",
    "def check_letter_and_number(df,columns):    \n",
    "    print(f'Кол-во уникальных значений: {df.select(columns).distinct().count()}')\n",
    "    print(f'Кол-во значений NaN: {df.select(columns).filter(col(columns).rlike(\"^[nan]*$|^[Nan]*$\")).count()}')\n",
    "    print(f'Кол-во с буквами : {df.select(columns).filter(col(columns).rlike(\"[A-Za-zА-Яа-яЁё]\")).count()}')\n",
    "    print(f'Кол-во уникальных с буквами : {df.select(columns).filter(col(columns).rlike(\"[A-Za-zА-Яа-яЁё]\")).distinct().count()}')\n",
    "    print(f'Кол-во с цифрами : {df.select(columns).filter(col(columns).rlike(\"[0-9]\")).count()}')\n",
    "    print(f'Кол-во уникальных с цифрами : {df.select(columns).filter(col(columns).rlike(\"[0-9]\")).distinct().count()}')\n",
    "#     print(f'Кол-во уникальных символы: {df.select(columns).filter(col(columns).rlike(\"^[^0-9][^A-Za-zА-Яа-яЁё]$\")).distinct().count()}')\n",
    "#     print(f'Кол-во значений пробелы $: {df.select(columns).filter(col(columns).rlike(\" $\")).count()}')\n",
    "#     print(f'Кол-во значений уникальных ^ пробелы: {df.select(columns).filter(col(columns).rlike(\" $\")).distinct().count()}')\n",
    "\n",
    "check_letter_and_number(df,col_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для простой чистки данных\n",
    "\n",
    "def clean_just(df,column):\n",
    "    df = df.withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "        .withColumn(column, F.regexp_replace(column, ' {1,} ',' '))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '^ ',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, ' $',''))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"^[nan]*$|^[Nan]*$|^[null]*$\"), 'UNKNOWN').otherwise(col(column)))\n",
    "\n",
    "    return df\n",
    "\n",
    "clean_just(df,'col')  #.select('col').distinct().show(100,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ban"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Где лежит черный список доменов (обновляется часто)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем файл txt в DataFrame\n",
    "df_txt = pd.read_csv(\"domens.txt\", sep=\"\\t\", header=None)\n",
    "# оборачиваем DataFrame в Spark DataFrame\n",
    "df_domens = spark_session.createDataFrame(df_txt.astype(str))\n",
    "# переименовываем колонку\n",
    "df_domens = df_domens.withColumnRenamed('0','domens_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домены департаментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем список рабочих доменов\n",
    "df_domen_job_orig = pd.read_excel(\"Domains2022.xlsx\", engine='openpyxl')\n",
    "\n",
    "# выводим общую информацию\n",
    "df_domen_job_orig.info()\n",
    "\n",
    "# выводим не обрезано 100 строчек\n",
    "# pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводим первые 4 значения\n",
    "df_domen_job_orig.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем лишние строчки\n",
    "df_domen_job_orig = df_domen_job_orig.drop(labels = [0,15],axis = 0)\n",
    "\n",
    "# создаем новый DataFrame pandas чтобы добавить почты mosgorzdrav.ru','mosmedzdrav.ru\n",
    "moszdrav = pd.DataFrame({'Name':['Неболей','Спорт'],\n",
    "                          'DomainName':['nebolei.ru','Sport.ru'],\n",
    "                        'DomainType':['Authoritative','Authoritative']})\n",
    "#  Добавляем новые почты\n",
    "df_domen_job_orig = df_domen_job_orig.append(moszdrav, ignore_index = True)\n",
    "\n",
    "# оборачиваем DataFrame в Spark DataFrame\n",
    "df_domen_job = spark_session.createDataFrame(df_domen_job_orig.astype(str)) \n",
    "\n",
    "# удаляем не нужную колонку\n",
    "df_domen_job = df_domen_job.drop('DomainType')\n",
    "# df_domen_job.show(2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ФИО"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем дубли в строке с ФИО\n",
    "\n",
    "# from pyspark.sql.functions import udf\n",
    "# remove = udf(lambda row: (sorted(set(row.split(' ')), key=row.index)), returnType=StringType())\n",
    "# df_join = udf(lambda row: (\" \".join(row)), returnType=StringType())\n",
    "# df_spark.withColumn(col_4, remove(col_4)).select(col_4)\\\n",
    "#     .withColumn(col_4, df_join(col_4)).select(col_4)\\\n",
    "#     .filter(col(col_4).rlike('Барсков')).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция проверки ФИО\n",
    "\n",
    "def check_fio(df,column): \n",
    "    sign = df.select(column).filter(col(column).rlike(\"._​\\'A-Za-z!@$%^&*()+=;:\\,/?\\|\\`~\\[\\]\\}\\{^\\'\\\"<>\")).count()\n",
    "    \n",
    "    print(f'Кол-во значений: {df.select(column).count()}')\n",
    "    print(f'Кол-во уникальных значений: {df.select(column).distinct().count()}')\n",
    "    print(f'Кол-во значений NaN: {df.select(column).filter(col(column).rlike(\"^[nan]*$\")).count()}')\n",
    "    print(f'Кол-во значений в начале пробелы: {df.select(column).filter(col(column).rlike(\"^ \")).count()}')\n",
    "    print(f'Кол-во значений пробелы в конце: {df.select(column).filter(col(column).rlike(\" $\")).count()}')\n",
    "    print(f'Кол-во значений с русскими буквами: {df.select(column).filter(col(column).rlike(\"[А-Яа-яЁё]+\")).count()}')\n",
    "    print(f'Кол-во значений с цифрами: {df.select(column).filter(col(column).rlike(\"[0-9]+\")).count()}')\n",
    "    print(f'Кол-во значений с латиницей и знаками: {sign}')\n",
    "    print(f'Странный пробел который не пробел : {df.select(column).filter(col(column).rlike(\" \")).count()}')\n",
    "    \n",
    "check_fio(df,col_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данные со знаком \"(\" (как мы видим данные после скобки нам не нужны в данном случае) но также\n",
    "# встречаются скобки среди фамилий(нужно понять где меньше потерь) тогда можно использовать удаление \"(\"\n",
    "\n",
    "# Обработка ФИО\n",
    "\n",
    "from pyspark.sql.functions import udf, initcap, regexp_extract\n",
    "remove = udf(lambda row: (sorted(set(row.split(' ')), key=row.index)), returnType=StringType())\n",
    "df_join = udf(lambda row: (\" \".join(row)), returnType=StringType())\n",
    "\n",
    "def clean_fio(df,column):\n",
    "    df = df.withColumn(column,split(df[column],'\\(').getItem(0))\n",
    "    df_fio = df.withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "        .withColumn(column, remove(column)).withColumn(column, df_join(column))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"^[nan]*$|^[Nan]*$|^[null]*$\"), '').otherwise(col(column)))\n",
    "    \n",
    "    df_fio = df_fio.withColumn(column, F.when(col(column).rlike(\"([0-9]+)\"),F.regexp_extract(column,\"(^[^\\s]*\\s[^\\s]*\\s[^\\s]*)\",1)).otherwise(col(column)))\n",
    "\n",
    "# для выполнения чтения перезаписываем в паркет(иногда без перезаписи все ломалось)\n",
    "#    df_fio.write.mode('overwrite').parquet('./df_parquet.parquet')\n",
    "#    df_fio = spark_session.read.parquet('./df_parquet.parquet')\n",
    "    \n",
    "    df_fio = df_fio.withColumn(column,F.regexp_replace(column, '[0-9._​\\'A-Za-z!@$#%^&*()+=;:\\,/?\\|\\`~\\[\\]{}^\\'\\\"<>]+',''))\\\n",
    "        .withColumn(column,F.regexp_replace(column, ' {1,}',' '))\\\n",
    "        .withColumn(column,F.regexp_replace(column, ' [А-Яа-яЁё]{1} ',' '))\\\n",
    "        .withColumn(column,F.regexp_replace(column, ' Отделение| отделение| Дмитровское|совм|осн|оциф|оц|ФИО|пользователь|Временный| Внешсовм| К-з| Учитель| Гдзс| Ст| Лицей| Воспитатель| Восп| Основ| Основной| Основное| Осн| Внешнее Сов-во| Отд Энергоресурсы| Основной Работник| Гимназия Гтро| Внешний Совм| Внешний Совместитель| Помощник Воспитателя| исп физ лицо| Исп Физ Лицо| Тхэквондо',''))\\\n",
    "        .withColumn(column,initcap(column))\\\n",
    "        .withColumn(column,F.regexp_replace(column, ' $',''))\\\n",
    "        .withColumn(column,F.regexp_replace(column, 'вн$','вна'))\\\n",
    "        .withColumn(column,F.regexp_replace(column, 'ви$','вич'))\\\n",
    "        .withColumn(column,F.regexp_replace(column, 'ова$','овна'))\\\n",
    "        .withColumn(column,F.regexp_replace(column, ' - |- | -','-'))\\\n",
    "        .withColumn(column,F.regexp_replace(column, ' {1,}',' '))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '^ ',''))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '[ ]$',''))\\\n",
    "        .withColumn(column, F.when(length(column) <= 5, 'UNKNOWN').otherwise(col(column)))\n",
    "        \n",
    "    return df_fio\n",
    "    \n",
    "clean_fio(df,col_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# КОММЕНТАРИИ К КОДУ ВЫШЕ\n",
    "\n",
    "# Обработка ФИО\n",
    "\n",
    "# чтобы убрать дубли в строке\n",
    "# разбиваем строку на слова и сортируем по индексу(слова возвращаем на свои места)\n",
    "remove = udf(lambda row: (sorted(set(row.split(' ')), key=row.index)), returnType=StringType())\n",
    "# собираем слова в строчку\n",
    "df_join = udf(lambda row: (\" \".join(row)), returnType=StringType())\n",
    ".withColumn(column, remove(column)).withColumn(column, df_join(column))\\\n",
    "\n",
    "def clean_fio(df,column):\n",
    "    # Откину все после знака '('\n",
    ".withColumn(column,split(df[column],'\\(').getItem(0))\n",
    "\n",
    "# удаляем странный пробел который не пробел(читается регуляркой как буква)\n",
    ".withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "\n",
    "# убираем дубли в строке используя переменные выше\n",
    ".withColumn(column, remove(column)).withColumn(column, df_join(column))\\\n",
    "\n",
    "# заменяем nan на знак '' \n",
    ".withColumn(column, F.when(col(column).rlike(\"^[nan]*$|^[Nan]*$|^[null]*$\"), '').otherwise(col(column)))\\\n",
    "\n",
    "# выбираем строчки с цифрами и забираем только первые три слова\n",
    "df_parquet = df.withColumn(column, F.when(col(column).rlike(\"([0-9]+)\"),F.regexp_extract(column,\"(^[^\\s]*\\s[^\\s]*\\s[^\\s]*)\",1))\\\n",
    "                .otherwise(col(column)))\\\n",
    "\n",
    "# для выполнения чтения перезаписываем в паркет(выше операция после выполнения без перезаписи все ломалось)\n",
    "df_parquet.write.mode('overwrite').parquet('./df_parquet.parquet')\n",
    "df = spark_session.read.parquet('./df_parquet.parquet')\n",
    "\n",
    "# Убрать все цифры,латиницу и знаки\n",
    ".withColumn(column,F.regexp_replace(column, '[0-9._​\\'A-Za-z!@#$%^&*()+=;:\\,/?\\|\\`~\\[\\]{}^\\'\\\"<>]+',''))\\\n",
    "\n",
    "# Убрать множественные пробелы\n",
    ".withColumn(column,F.regexp_replace(column, ' {1,}',' '))\\\n",
    "\n",
    "# В единичном виде знаки и слова убрать\n",
    ".withColumn(column,F.regexp_replace(column, ' [А-Яа-яЁё]{1} ',' '))\\\n",
    "\n",
    "# Убрать лишние слова(то что нашел в таблицах)\n",
    ".withColumn(column,F.regexp_replace(column, ' Отделение| отделение| Дмитровское|совм|осн|оциф|оц|ФИО|пользователь|Временный| Внешсовм| К-з| Учитель| Гдзс| Ст| Лицей| Воспитатель| Восп| Основ| Основной| Основное| Осн| Внешнее Сов-во| Отд Энергоресурсы| Основной Работник| Гимназия Гтро| Внешний Совм| Внешний Совместитель| Помощник Воспитателя| исп физ лицо| Исп Физ Лицо| Тхэквондо',''))\\\n",
    "\n",
    "# Выбрать регистр для слов(Первая буква в верхнем регистре)\n",
    ".withColumn(column,initcap(column))\\\n",
    "\n",
    "# Убрать пробелы, поменять окончания вн и ви на вна и вич\n",
    ".withColumn(column,F.regexp_replace(column, ' $',''))\\\n",
    ".withColumn(column,F.regexp_replace(column, 'вн$','вна'))\\\n",
    ".withColumn(column,F.regexp_replace(column, 'ви$','вич'))\\\n",
    ".withColumn(column,F.regexp_replace(column, 'ова$','овна'))\\\n",
    "\n",
    "# Убрать пробелы в начале и в конце\n",
    ".withColumn(column,F.regexp_replace(column, '^[ ]',''))\\\n",
    ".withColumn(column,F.regexp_replace(column, '[ ]$',''))\\\n",
    "\n",
    "# Убрать лишние пробелы около тире\n",
    ".withColumn(column,F.regexp_replace(column, ' - ','-'))\\\n",
    "\n",
    "# заменяем все что меньше или равно 5-ти кол-во символов на UNKNOWN\n",
    ".withColumn(column, F.when(length(column) <= 5, 'UNKNOWN').otherwise(col(column)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'СНИЛС'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для очистки СНИЛС\n",
    "\n",
    "def clean_snils(df,column):\n",
    "    df_correct = df.withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '^ {0,}',''))\\\n",
    "        .withColumn(column,F.regexp_replace(column, ' {0,}$',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '^[!@#$%^&*()+=;:,-/?\\|\\` ~\\[\\]{}^\\'\\\"<>]+$',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '[- ]+',''))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '^[nan]*$|^[Nan]*$|^[null]*$','UNKNOWN'))\\\n",
    "        .withColumn(column, F.when(length(column) < 11, 'UNKNOWN').when(length(column) > 11, 'UNKNOWN').otherwise(col(column)))\n",
    "    \n",
    "    return df_correct\n",
    "\n",
    "clean_snils(df_spark,col_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'ДР'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нужно смотреть формат написания \n",
    "# 07.11.1983\n",
    "# 1983-11-07\n",
    "# 07-11-1983\n",
    "# 1993-06-10 00:00:00\n",
    "\n",
    "# df_spark.withColumn(col_6,F.regexp_replace(col_6, '^[nan]*$|^[Nan]*$|^[null]*$','UNKNOWN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-ое решение через date_format и to_date\n",
    "\n",
    "# Функция для ДР и Даты выдачи паспорта\n",
    "# приводим к формату dd.MM.yyyy(07.01.1996)\n",
    "# from pyspark.sql.functions import to_date, date_format,date_add\n",
    "\n",
    "def format_dr(df,column):\n",
    "        if df.select(column).filter(col(column).rlike('\\d\\d\\d\\d-\\d\\d\\-\\d\\d')).count() > 1000:\n",
    "            df = df.withColumn(column, date_format(col(column),\"dd.MM.yyyy\"))\n",
    "        elif df.select(column).filter(col(column).rlike('\\d\\d\\d\\d.\\d\\d\\.\\d\\d')).count() > 1000:\n",
    "            df = df.withColumn(column, date_format(col(column),\"dd.MM.yyyy\"))\n",
    "        elif df.select(column).filter(col(column).rlike('\\d{2}\\-\\d{2}\\-\\d{4}')).count() > 1000:\n",
    "            df = df.withColumn(column, date_format(col(column),\"dd.MM.yyyy\"))\n",
    "        elif df.select(column).filter(col(column).rlike('\\d{2}\\.\\d{2}\\.\\d{4}')).count() > 1000:\n",
    "            df = df.withColumn(column, to_date(col(column),\"dd.MM.yyyy\"))\\\n",
    "                .withColumn(column, date_format(col(column),\"dd.MM.yyyy\"))\n",
    "        df = df.withColumn(column, F.when(col(column).isNull(), 'UNKNOWN').otherwise(col(column)))\n",
    "        return df\n",
    "        \n",
    "format_dr(df_spark,col_6) #.select(col_6).show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-ое решение через регулярки\n",
    "\n",
    "# Функция для ДР и Даты выдачи паспорта\n",
    "# приводим к формату dd.MM.yyyy(07.01.1996)\n",
    "\n",
    "def format_dr(df,column):\n",
    "        df = df.withColumn(column,F.regexp_replace(column, '^[nan]*$|^[Nan]*$|^[null]*$','UNKNOWN'))\\\n",
    "            .withColumn(column, F.regexp_replace(column, ' +',''))\n",
    "        \n",
    "        if df.select(column).filter(col(column).rlike('\\d\\d\\d\\d-\\d\\d\\-\\d\\d')).count() > 1000:\n",
    "            df = df.withColumn(column, F.regexp_replace(column, '(\\d{4})\\-(\\d{2})\\-(\\d{2})','$3.$2.$1'))\n",
    "        elif df.select(column).filter(col(column).rlike('\\d{4}\\.\\d{2}\\.\\d{2}')).count() > 1000:\n",
    "            df = df.withColumn(column, F.regexp_replace(column, '(\\d{4})\\.(\\d{2})\\.(\\d{2})','$3.$2.$1'))\n",
    "        elif df.select(column).filter(col(column).rlike('\\d{2}\\-\\d{2}\\-\\d{4}')).count() > 1000:\n",
    "            df = df.withColumn(column, F.regexp_replace(column, '[-]','.'))\n",
    "                \n",
    "        \n",
    "        df = df.withColumn(column, col(column).substr(0, 10))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "format_dr(df_spark,col_6) #.select(col_6).filter(col(col_6).rlike('UNKNOWN')).show(3,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'ТипДУЛ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ТипДУЛ (долго выполняется обработка(больше 30 мин) c 1 млн. строк)\n",
    "# Вариант разбить на несколько функции или использовать persist()\n",
    "# можно промежуточно перезаписывать в паркет и читать их сразу.\n",
    "\n",
    "def tipdul(df,column):\n",
    "    df.withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "        .withColumn(column, F.regexp_replace(column, ' {1,}',' '))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '^ | $',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, 'Форма представления сведений','UNKNOWN'))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"Паспорт СССР|паспорт СССР|Паспорт гражданина СССР\"), 'Паспорт гражданина СССР').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"ПАСПОРТ РОССИИ|Паспорт гражданина РФ|Паспорт гражданина России|^паспорт РФ$|^Паспорт РФ$|^паспорт гражданина РФ$|^Паспорт гражданина РФ$|^Паспорт гражданина Российской Федерации$|^паспорт гражданина Российской Федерации$\"), 'Паспорт гражданина РФ').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"^Заграничный паспорт гражданина Р|^Загранпаспорт гражданина Р\"), 'Загранпаспорт гражданина РФ').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"Туркменистана|Заграничный паспорт гражданина иностранного государства|Белоруси|Паспорт гражданина Азербайджана|Паспорт гражданина Армении|аспорт Гражданина Украины|аспорт гражданина Украины|Республики|^паспорт иностранного|^Паспорт иностранного|ностранный паспорт|^Паспорт гражданина иностранного\"), 'Паспорт гражданина иностранного государства').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"Документ иностранного гражданина\"), 'Документ иностранного гражданина').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"Паспорт моряка|^паспорт$|^Паспорт$\"), 'Паспорт').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"ВИД НА ЖИТЕЛЬ|ид на жител\"), 'Вид на жительство').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"Иные докум|Трудовая книжка|Свидетельство о перемене имени|Свидетельство о регистрации по месту пребывания|Справка об освобождении|Полис ДМС|Страховой полис обязательного медицинского страхования гражданина Российской Федерации|Свидетельство о расторжении брака|основное|Водительское удостоверение|Полис ОМС|Патент|Свидетельство о заключении брака\"), 'Иные документы').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"Военный билет|Временное удостоверение, выданное взамен военного билета\"), 'Военный билет').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"Разрешение на врем\"), 'Разрешение на временное проживание в РФ').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"Свидетельство о рождении\"), 'Свидетельство о рождении').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"Временное удостоверение\"), 'Временное удостоверение').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(length(column) < 4, 'UNKNOWN').otherwise(col(column)))\n",
    "            \n",
    "    return df\n",
    "\n",
    "tipdul(df,col_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Документ_Серия'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция чистки Документ_Серия\n",
    "\n",
    "def clean_doc(df,column):\n",
    "    df_correct = df.withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '^ {0,}| {0,}$',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '^[!@#$%^&*()+=;:,-/?\\|\\` ~\\[\\]{}^\\'\\\"<>]+$',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '[- ]+',''))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '^[nan]*$|^[Nan]*$|^[null]*$','UNKNOWN'))\n",
    "    \n",
    "    return df_correct\n",
    "\n",
    "clean_snils(df_spark,col_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'>Phones</font>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для проверки ошибок в данных\n",
    "\n",
    "def check_phones(df,column):\n",
    "    print(f'Кол-во значений NaN: {df.select(column).filter(col(column).rlike(\"^[nan]*$|^[Nan]*$\")).count()}')\n",
    "    print(f'Кол-во значений с цифрами: {df.select(column).filter(col(column).rlike(\"[0-9]+\")).count()}')\n",
    "    print(f'Кол-во уникальных значений с цифрами: {df.select(column).filter(col(column).rlike(\"[0-9]+\")).distinct().count()}')\n",
    "    print(f'Кол-во тел. не соответствуют ^+ : {df.select(column).filter(col(column).rlike(\"^[^+]\")).count()}')\n",
    "    print(f'Кол-во уникальных не соответствуют ^+ : {df.select(column).filter(col(column).rlike(\"^[^+]\")).distinct().count()}')\n",
    "    print(f'Кол-во номеров с буквами : {df.select(column).filter(col(column).rlike(\"[A-Za-zА-Яа-яЁёёЁ]\")).count()}')\n",
    "    print(f'Кол-во уникальных номеров с буквами : {df.select(column).filter(col(column).rlike(\"[A-Za-zА-Яа-яЁёёЁ]\")).distinct().count()}')\n",
    "    print(f'Кол-во номеров с символами : {df.select(column).filter(col(column).rlike(\"^[^+]*$\")).count()}')\n",
    "    print(f'Кол-во уникальных с символами : {df.select(column).filter(col(column).rlike(\"^[^+]*$\")).distinct().count()}')\n",
    "    print(f'Странный пробел который не пробел : {df.select(column).filter(col(column).rlike(\" \")).count()}')\n",
    "    \n",
    "check_phones(df_spark,col_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# приводим все телефоны к единому формату +74957773388\n",
    "# в строке попадаются \"сестра,мама\" владалец телефона(выносим в отдельную колонку 'Владелец_телефона')\n",
    "\n",
    "def clean_mobile_number(df,column,newcolumn):\n",
    "    # дублируем колонку\n",
    "    df_mobile = df.withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "        .withColumn(newcolumn,col(column))\\\n",
    "        .withColumn(newcolumn,F.regexp_replace(newcolumn, '[0-9+)t,¶№&;?*/|` --.—\\=:(][ -]*','9'))\\\n",
    "        .withColumn(newcolumn,F.regexp_replace(newcolumn, '[9]+',' '))\\\n",
    "        .withColumn(newcolumn,F.regexp_replace(newcolumn, '^ {1,}| {1,}$',''))\\\n",
    "        .withColumn(newcolumn, F.when(length(newcolumn) < 2, 'UNKNOWN')\\\n",
    "                    .when(length(newcolumn) > 14, 'UNKNOWN').otherwise(col(newcolumn)))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '[A-Za-zА-Яа-яЁёёЁ]',''))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '[¶№!@#$%^&*.\\)\\(\\+=—;:,\\-/?\\|\\` ~\\[\\]{}^\\'\\’\\\"<>]+',''))\\\n",
    "        .withColumn(column, F.when(length(column) < 2, 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '^[8]',''))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '^[7]',''))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"^[0123567]\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(length(column) <= 9, 'UNKNOWN').when(length(column) >= 11, 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '^','+7'))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"[A-Za-zА-Яа-яЁёёЁ]\"), 'UNKNOWN').otherwise(col(column)))\n",
    "    \n",
    "    return df_mobile\n",
    "\n",
    "clean_mobile_number(df_spark,col_13,'Владелец_телефона')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# описание к функции выше\n",
    "\n",
    "def clean_mobile_number(df,column,newcolumn):\n",
    "    # удаляем пробел который не пробел(пробел видится как знак, два слова видятся как одно)\n",
    "    .withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "    # дублируем колонку\n",
    "    df_mobile = df.withColumn(newcolumn,col(column))\\\n",
    "    # превращаем все символы кроме букв превращаем в цифру 9\n",
    "    .withColumn(newcolumn,F.regexp_replace(newcolumn, '[0-9+)t,¶№&;?*/|` --.—\\=:(][ -]*','9'))\\\n",
    "    # все 9 превращаем в пробел\n",
    "    .withColumn(newcolumn,F.regexp_replace(newcolumn, '[9]+',' '))\\\n",
    "    # убираем пробелы в начале и конце\n",
    "    .withColumn(newcolumn,F.regexp_replace(newcolumn, '^ {1,}| {1,}$',''))\\\n",
    "    # затем все что меньше 2-ух знаков и больше 14-ти переводим в UNKNOWN\n",
    "    .withColumn(newcolumn, F.when(length(newcolumn) < 2, 'UNKNOWN')\\\n",
    "                .when(length(newcolumn) > 14, 'UNKNOWN').otherwise(col(newcolumn)))\\\n",
    "    # удаляем все символы и букв кроме цифр\n",
    "    .withColumn(column,F.regexp_replace(column, '[A-Za-zА-Яа-яЁёёЁ]',''))\\\n",
    "    # удаляем посторонние символы\n",
    "    .withColumn(column,F.regexp_replace(column, '[¶№!@#$%^&*.\\)\\(\\+=—;:,\\-/?\\|\\` ~\\[\\]{}^\\'\\’\\\"<>]+',''))\\\n",
    "     # удаляем все что меньше 2-ух знаков\n",
    "    .withColumn(column, F.when(length(column) < 2, 'UNKNOWN').otherwise(col(column)))\\\n",
    "    # удаляем цифру восемь в начале\n",
    "    .withColumn(column,F.regexp_replace(column, '^[8]',''))\\\n",
    "    # удаляем цифру семь в начале\n",
    "    .withColumn(column,F.regexp_replace(column, '^[7]',''))\\\n",
    "    # удаляем всё что не начинается на 4,8,9\n",
    "    .withColumn(column, F.when(col(column).rlike(\"^[0123567]\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "    # затем все что меньше 9-ти знаков и больше 11-ти переводим в UNKNOWN\n",
    "    .withColumn(column, F.when(length(column) <= 9, 'UNKNOWN').when(length(column) >= 11, 'UNKNOWN').otherwise(col(column)))\\\n",
    "    # подставляем +7 в начале\n",
    "    .withColumn(column,F.regexp_replace(column, '^','+7'))\\\n",
    "    # меняем любые совпадения букв на UNKNOWN\n",
    "    .withColumn(column, F.when(col(column).rlike(\"[A-Za-zА-Яа-яЁёёЁ]+\"), 'UNKNOWN').otherwise(col(column)))\n",
    "    \n",
    "    return df_mobile\n",
    "\n",
    "clean_mobile_number(df_spark,col_13,'Владелец_телефона') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Номер_телефонаРабочий'  \n",
    "попадается добавочный номер(выносим в отдельную колонку)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# приводим все телефоны к единому формату +74957778811\n",
    "# в строке попадаются \"доб.\" разделяем по слову \"доб.\"\n",
    "# добавочный телефон выносим в отдельную колонку 'Внутреннийтел'\n",
    "\n",
    "def clean_telefone_number(df,column,word,newcolumn):\n",
    "    # Разделение колонки на две по слову\n",
    "    df_correct = df.withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "        .withColumn(newcolumn,split(df[column],word).getItem(1))\\\n",
    "        .withColumn(newcolumn,F.regexp_replace(newcolumn, '[+)t,¶№&;?*/|` --.—\\=:(][ -]*',''))\\\n",
    "        .withColumn(newcolumn,F.regexp_replace(newcolumn, '[A-Za-zА-Яа-яЁёёЁ]+',''))\\\n",
    "        .na.fill('UNKNOWN', newcolumn)\\\n",
    "        .withColumn(column,split(df[column],word).getItem(0))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '[A-Za-zА-Яа-яЁёёЁ]',''))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '[¶№!@#$%^&*.\\)\\(\\+=—;:,\\\\-/?\\|\\` ~\\[\\]{}^\\'\\’\\\"<>]+',''))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '^[8]',''))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '^[7]',''))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"^[0123567]\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(length(column) <= 9, 'UNKNOWN').when(length(column) >= 11, 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column,F.regexp_replace(column, '^','+7'))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"[A-Za-zА-Яа-яЁёёЁ]\"), 'UNKNOWN').otherwise(col(column)))\n",
    "    \n",
    "    return df_correct\n",
    "\n",
    "clean_telefone_number(df_spark,col_14,'доб','Внутреннийтел')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОПИСАНИЕ к функции выше\n",
    "\n",
    "def clean_telefone_number(df,column,word,newcolumn):\n",
    "    # удаляем пробел который не пробел\n",
    "    .withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "    # Разделение колонку на две по знаку 'доб',вторая колонка\n",
    "    df_correct = df.withColumn(newcolumn,split(df[column],word).getItem(1))\\\n",
    "    # удаляем все лишнее (Символы) в второй колонке\n",
    "    .withColumn(newcolumn,F.regexp_replace(newcolumn, '[¶№!@#$%^&*.\\)\\(\\+=—;:,\\\\-/?\\|\\` ~\\[\\]{}^\\'\\’\\\"<>]+',''))\\\n",
    "    # удаляем все лишнее (буквы) в второй колонке\n",
    "    .withColumn(newcolumn,F.regexp_replace(newcolumn, '[A-Za-zА-Яа-яЁёёЁ]+',''))\\\n",
    "    # заменяем в колонке \"Внутреннийтел\" значения null на UNKNOWN\n",
    "    .na.fill('UNKNOWN', newcolumn)\\\n",
    "    # первая до знака 'доб'\n",
    "    .withColumn(column,split(df[column],word).getItem(0))\\\n",
    "    # удаляем все лишнее (Символы) в первой колонке\n",
    "    .withColumn(column,F.regexp_replace(column, '[¶№!@#$%^&*.\\)\\(\\+=—;:,\\\\-/?\\|\\` ~\\[\\]{}^\\'\\’\\\"<>]+',''))\\\n",
    "    # удаляем все лишнее (буквы) в первой колонке\n",
    "    .withColumn(column,F.regexp_replace(column, '[A-Za-zА-Яа-яЁёёЁ]',''))\\\n",
    "    # удаляем 8 в начале\n",
    "    .withColumn(column,F.regexp_replace(column, '^[8]',''))\\\n",
    "    # удаляем 7 в начале\n",
    "    .withColumn(column,F.regexp_replace(column, '^[7]',''))\\\n",
    "    # заменям значения начало которых начинается на 0,1,2,3,5,6,7 на значение 'UNKNOWN'\n",
    "    .withColumn(column, F.when(col(column).rlike(\"^[0123567]\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "    # затем все что меньше 9-ти знаков и больше 11-ти переводим в UNKNOWN\n",
    "    .withColumn(column, F.when(length(column) <= 9, 'UNKNOWN').when(length(column) >= 11, 'UNKNOWN').otherwise(col(column)))\\\n",
    "    # подставляем +7 в начале\n",
    "    .withColumn(column,F.regexp_replace(column, '^','+7'))\\\n",
    "    # меняем любые совпадения букв на UNKNOWN\n",
    "    .withColumn(column, F.when(col(column).rlike(\"[A-Za-zА-Яа-яЁёёЁ]\"), 'UNKNOWN').otherwise(col(column)))\n",
    "\n",
    "    return df_correct\n",
    "\n",
    "# 1-таблица, 2-колонку, 3-слово разделитель колонки, 4-название новой колонки(в которую записываем добав)\n",
    "clean_telefone_number(df_spark,col_14,'доб','Внутреннийтел')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Список доменов по рабочей почте\n",
    "\n",
    "df_domen_excel_orig = pd.read_excel(\"Domains2022.xlsx\", engine='openpyxl')\n",
    "df_domen_excel_orig.info()\n",
    "\n",
    "# pd.options.display.max_rows = 100\n",
    "# df_domen_excel_orig.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_domen_job_orig = df_domen_excel_orig.drop(labels = [0,15],axis = 0)\n",
    "\n",
    "# создаем новый DataFrame pandas чтобы добавить почты mosgorzdrav.ru','mosmedzdrav.ru\n",
    "moszdrav = pd.DataFrame({'Name':['Мосгорздрав','Мосмедздрав'],\n",
    "                          'DomainName':['mosgorzdrav.ru','mosmedzdrav.ru'],\n",
    "                        'DomainType':['Authoritative','Authoritative']})\n",
    "#  Добавляем новые почты\n",
    "df_domen_job_orig = df_domen_job_orig.append(moszdrav, ignore_index = True)\n",
    "\n",
    "df_domen_job = spark_session.createDataFrame(df_domen_job_orig.astype(str)) \n",
    "\n",
    "df_domen_job = df_domen_job.drop('DomainType')\n",
    "# df_domen_excel.show(82,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для проверки ошибок в данных рабочей почты\n",
    "\n",
    "def email_job_check(df,columns):\n",
    "    # Кол-во c символами '.-><_' в начале\n",
    "    sign_start = df.select(columns).filter(col(columns).rlike('^[!@#$%^&*()+=;:,/?\\|\\`~\\[\\]{}^\\'\\\"<>]+')).count()\n",
    "    # Кол-во c символами '.-><_' в конце\n",
    "    sign_end = df.select(columns).filter(col(columns).rlike('[!@#$%^&*()+=;:,/?\\|\\`~\\[\\]{}^\\'\\\"<>]+$')).count()\n",
    "    # Кол-во строк с пробелами и знаком ¶\n",
    "    probel = df.select(columns).filter(col(columns).rlike(' |¶|\\\\|#|\\/|\\\"\\'\\`')).count()\n",
    "    domen_mos = df.withColumn('domen',split(F.col(columns), '@')[1]).select('domen').filter(col('domen').rlike('(?i)mos')).count()\n",
    "    domen_mos_distinct = df.withColumn('domen',split(F.col(columns), '@')[1]).select('domen').filter(col('domen').rlike('(?i)mos')).distinct().count()\n",
    "    backslash = df.select(columns).filter(col(columns).rlike('<|>|\\)|\\(')).count()  \n",
    "    \n",
    "    print(f\"Кол-во значений : {df.select(columns).count()}\")\n",
    "    print(f\"Кол-во c 'nan' и 'null' : {df.select(columns).filter(col(columns).rlike('^[nan]*$|^[Nan]*$|^[null]*$|^[null]*$')).count()}\")\n",
    "    print(f\"Кол-во строк с пробелами и знаком ¶ : {probel}\")\n",
    "    print(f\"Кол-во строк без '@' : {df.select(columns).filter(col(columns).rlike('^[^@]+$')).count()}\")\n",
    "    print(f\"Кол-во строк c двойными '@@' и больше : {df.select(columns).filter(col(columns).rlike('[@]{2,}+')).count()}\")\n",
    "    print(f\"Кол-во строк c двумя '@' в строке и больше : {df.select(columns).filter(col(columns).rlike('[@]+[А-Яа-яЁёA-Za-z0-9_,.; :<>]+[@]+')).count()}\")\n",
    "    print(f\"Кол-во строк почт без точек после '@' : {df.select(columns).filter(col(columns).rlike('@[^.]+$')).count()}\")\n",
    "    print(f\"Кол-во только русские буквы и цифры с пробелом : {df.select(columns).filter(col(columns).rlike('^[А-Яа-яЁё 0-9]+$')).count()}\")\n",
    "    print(f\"Кол-во c символами '.\\/,->+*<_#' в начале : {sign_start}\")\n",
    "    print(f\"Кол-во c символами '.\\/,->+*<_#' в конце : {sign_end}\")\n",
    "    print(f\"Кол-во c символами '<>)('  : {backslash}\")\n",
    "    print(f\"Кол-во заканчивается на r или ry : {df.select(columns).filter(col(columns).rlike('(?i)[.]r$|(?i)[.]ry$')).count()}\")\n",
    "    print(f\"Кол-во рабочих почт в домене есть 'mos'  : {domen_mos}\")\n",
    "    print(f\"Кол-во рабочих почт в домене уникальных есть 'mos'  : {domen_mos_distinct}\")\n",
    "    print(f\"Кол-во строк со словом 'e-mail:'  : {df.select(columns).filter(col(columns).rlike('e-mail:')).count()}\")\n",
    "    print(f'Странный пробел который не пробел : {df.select(column).filter(col(column).rlike(\" \")).count()}')\n",
    "    \n",
    "    if df.select(columns).filter(col(columns).rlike('\\)|\\(')).distinct().count() >= 1:\n",
    "        df.select(columns).filter(col(columns).rlike('\\)|\\(')).distinct().show(2,False)\n",
    "    if df.select(columns).filter(col(columns).rlike('<|>')).distinct().count() >= 1:\n",
    "        df.select(columns).filter(col(columns).rlike('<|>')).distinct().show(2,False)\n",
    "    if df.select(columns).filter(col(columns).rlike('e-mail:')).distinct().count() >= 1:\n",
    "        df.select(columns).filter(col(columns).rlike('e-mail:')).distinct().show(2,False)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "email_job_check(df_spark,col_15)\n",
    "# df_spark.select(col_16).filter(col(col_16).rlike('e-mail:')).distinct().show(413,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка рабочих почт\n",
    "\n",
    "def clean_job_email(df,column,df_job):\n",
    "    df_email = df.withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"^[^@]*$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.regexp_replace(column, ' |¶|\\\\|#|\\/|\\\"\\'\\`',''))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"@[^.]+$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"[@]{2,}+\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"[@]+[А-Яа-яЁёA-Za-z0-9_,.; :<>]+[@]+\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.regexp_replace(column, 'e-mail:',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '^[!@#$%^&*()+=;:,/?\\|\\` ~\\[\\]{}^\\'\\\"<>]+',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '[!@#$%^&*()+=;:,/?\\|\\` ~\\[\\]{}^\\'\\\"<>]+$',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '(?i)[.]r$|(?i)[.]ry$','.ru'))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '(?i)moc.ru$','mos.ru'))\n",
    "    \n",
    "    df_email = df_email.withColumn('domen',split(F.col(column), '@')[1])\\\n",
    "        .withColumn('domen', F.regexp_replace('domen', '^[¶!@#$%^&*()+=;\\- :.,/?\\|\\`~\\[\\]{}^\\'\\\"<>]',''))\\\n",
    "        .withColumn('domen', F.regexp_replace('domen', '[А-Яа-яЁё¶!@#$%^&*()+=;\\- :.,/?\\|\\`~\\[\\]{}^\\'\\\"<>]+$',''))\\\n",
    "        .withColumn('domen', F.regexp_replace('domen', '(?i)[.]r$|(?i)[.]ry$|(?i)[.]u$','.ru'))\\\n",
    "        .withColumn('mos', F.when(col('domen').rlike('(?i)mos|(?i)russpass'), '#').otherwise('UNKNOWN'))\\\n",
    "        .withColumn(column, F.when(col('mos').rlike(\"[^#]\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .drop('mos')\n",
    "    \n",
    "    df_email = df_email.join(df_job, df_email.domen==df_job.DomainName,'left')\\\n",
    "        .withColumn(column, F.when(col('DomainName').isNull(), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .drop('domen', 'DomainName','Name')\n",
    "        \n",
    "    return df_email\n",
    "\n",
    "clean_job_email(df_spark,col_15,df_domen_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание функции рабочей почты\n",
    "\n",
    "def clean_job_email(df,column,df1):\n",
    "    # Удаляем пробел который не пробел\n",
    "    df_email = df.withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "        # Убираем почты без знака \"@\"\n",
    "        .withColumn(column, F.when(col(column).rlike(\"^[^@]*$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        # Убираем все пробелы и\n",
    "        .withColumn(column, F.regexp_replace(column, ' |¶|\\\\|#|\\/|\\\"\\'\\`',''))\\\n",
    "        # Убираем почты без точек после \"@\"\n",
    "        .withColumn(column, F.when(col(column).rlike(\"@[^.]+$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        # Убираем если двойная \"@@\" и больше\n",
    "        .withColumn(column, F.when(col(column).rlike(\"[@]{2,}$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        # Убираем если больше двух \"@\" \n",
    "        .withColumn(column, F.when(col(column).rlike(\"[@]+[А-Яа-яA-Za-z0-9_,.; :<>]+[@]+\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        # Убираем \"e-mail:\" \n",
    "        .withColumn(column, F.regexp_replace(column, 'e-mail:',''))\n",
    "        # Убираем символы в начале почты(точки и запятые)\n",
    "        .withColumn(column, F.regexp_replace(column, '^[!@#$%^&*()+=;:,/?\\|\\` ~\\[\\]{}^\\'\\\"<>]+',''))\\\n",
    "         # Убираем символы в конце почты(точки и запятые)\n",
    "        .withColumn(column, F.regexp_replace(column, '[!@#$%^&*()+=;:,/?\\|\\` ~\\[\\]{}^\\'\\\"<>]+$',''))\\\n",
    "        # Добавляем к \"r\" + \"u\" = ru\n",
    "        .withColumn(column, F.regexp_replace(column, '(?i)[.]r$|(?i)[.]ry$','.ru'))\\\n",
    "        # Заменяем moc.ru на mos.ru\n",
    "        .withColumn(column, F.regexp_replace(column, '(?i)moc.ru$','mos.ru'))\n",
    "        # создаем колонку только домен второго уровня для проверки в забанненых\n",
    "    df_email = df_email.withColumn('domen',split(F.col(col_16), '@')[1])\\\n",
    "         # Убираем символы в начале домена (точки и запятые)\n",
    "        .withColumn('domen', F.regexp_replace('domen', '^[¶!@#$%^&*()+=;:,/?\\|\\`~\\[\\]{}^\\'\\\"<>]',''))\\\n",
    "        # Убираем символы в конце домена (точки и запятые)\n",
    "        .withColumn('domen', F.regexp_replace('domen', '[¶!@#$%^&*()+=;:,/?\\|\\`~\\[\\]{}^\\'\\\"<>]+$',''))\\\n",
    "        # Добавляем к \"r\" + \"u\" = ru\n",
    "        .withColumn('domen', F.regexp_replace('domen', '(?i)[.]r$|(?i)[.]ry$','.ru'))\\\n",
    "        # (оставляем только раб домены)Выбираем домены с mos и назначаем их # остальные UNKNOWN\n",
    "        .withColumn('mos', F.when(col('domen').rlike('(?i)mos'), '#').otherwise('UNKNOWN'))\\\n",
    "        # (удаляем все не раб домены)Выбираем почты с mos без # и заменяем в почте как UNKNOWN\n",
    "        .withColumn(column, F.when(col('mos').rlike(\"[^#]\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "         # Удаляем колонку mos\n",
    "        .drop('mos')\n",
    "        # Джойним список с доменами второго уровня которые забаннены\n",
    "    df_email = df_email.join(df1, df_email.domen==df1.domens_1,'left')\\\n",
    "        # В колонке 'column' убираем почты если они есть в колонке забанных\n",
    "        .withColumn(column, F.when(col('domens_1').isNotNull(), 'ban_SUDIR').otherwise(col(column)))\\\n",
    "        # Удаляем колонки которые добавили в текущей функции\n",
    "        .drop('domen', 'domens_1')\n",
    "    \n",
    "    return df_email\n",
    "clean_job_email(df_spark,col_16,df_domens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green'>Email Личный</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем файл TXT с забаннеными доменами второго уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt = pd.read_csv(\"domens.txt\", sep=\"\\t\",header= None)\n",
    "df_domens = spark_session.createDataFrame(df_txt.astype(str))\n",
    "df_domens = df_domens.withColumnRenamed('0','domens_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "спарта-кфкс.рф\n"
     ]
    }
   ],
   "source": [
    "# Заменяем Punycode на его расшифровку\n",
    "import idna\n",
    "print (idna.decode('xn----7sba5bazifhfz.xn--p1ai'))\n",
    "\n",
    "# Punycode конвертер для доменов 2 уровня типа - 'xn----7sba5bazifhfz.xn--p1ai'\n",
    "# на выходе получаем - 'спарта-кфкс.рф'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.reg.ru/web-tools/punycode?_gl=1*1s9u8xp*_ga*NDc2MTA4MzE1LjE2NDA4NjA0OTc.*_ga_N9GCQPR82H*MTY0MTM4MDM0MC40LjAuMTY0MTM4MDM0MC42MA.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(?i) - Использовать соответствие без учета регистра"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список часто используемых доменов для личной почты\n",
    "\n",
    "rambler.ru  \n",
    "rambler.ua  \n",
    "ro.ru  \n",
    "lenta.ru  \n",
    "autorambler.ru  \n",
    "myrambler.ru  \n",
    "  \n",
    "mail.ru  \n",
    "list.ru  \n",
    "bk.ru  \n",
    "internet.ru  \n",
    "inbox.ru  \n",
    "\n",
    "gmail.com  \n",
    "googlemail.com  \n",
    "\n",
    "yandex.ru  \n",
    "yandex.by  \n",
    "yandex.ua  \n",
    "yandex.kz  \n",
    "yandex.com  \n",
    "ya.ru  \n",
    "narod.ru  \n",
    "\n",
    "YAHOO  \n",
    "rocketmail.com  \n",
    "yahoo.com  \n",
    "ymail.com  \n",
    "\n",
    "MICROSOFT  \n",
    "hotmail.com  \n",
    "live.com  \n",
    "outlook.com\n",
    "\n",
    "https://developer.roman.grinyov.name/blog/92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заготовки по почтам\n",
    "# находим русские буквы и удаляем буквы\n",
    "# пример: на входе - \"олдлод@mail.ru\" \n",
    "#         на выходе - \"@mail.ru\"\n",
    "\n",
    "# rambler.ru\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@myrambler.ru)|(?i)[А-Яа-яЁё]+(?=@autorambler.ru)|(?i)[А-Яа-яЁё]+(?=@lenta.ru)|(?i)[А-Яа-яЁё]+(?=@ro.ru)|(?i)[А-Яа-яЁё]+(?=@rambler.ua)|(?i)[А-Яа-яЁё]+(?=@rambler.ru)',''))\\\n",
    "# mail.ru\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@mail.ru)|(?i)[А-Яа-яЁё]+(?=@list.ru)|(?i)[А-Яа-яЁё]+(?=@bk.ru)|(?i)[А-Яа-яЁё]+(?=@internet.ru)|(?i)[А-Яа-яЁё]+(?=@inbox.ru)',''))\\\n",
    "# gmail.com\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@gmail.com)|(?i)[А-Яа-яЁё]+(?=@googlemail.com)',''))\\\n",
    "# yandex.ru\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@yandex.ru)|(?i)[А-Яа-яЁё]+(?=@yandex.by)|(?i)[А-Яа-яЁё]+(?=@yandex.ua)|(?i)[А-Яа-яЁё]+(?=@yandex.kz)|(?i)[А-Яа-яЁё]+(?=@yandex.com)|(?i)[А-Яа-яЁё]+(?=@ya.ru)|(?i)[А-Яа-яЁё]+(?=@narod.ru)',''))\\\n",
    "# yahoo.com\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@ymail.com)|(?i)[А-Яа-яЁё]+(?=@rocketmail.com)|(?i)[А-Яа-яЁё]+(?=@yahoo.com)',''))\\\n",
    "# MICROSOFT\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@hotmail.com)|(?i)[А-Яа-яЁё]+(?=@live.com)|(?i)[А-Яа-яЁё]+(?=@outlook.com)',''))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заготовки по почтам\n",
    "# находим русские буквы и удаляем буквы\n",
    "# пример: на входе - \"ДМШ имени М.Л. Таривердиева <dmsh37@mail.ru\"   \n",
    "#         на выходе - \"..dmsh37@mail.ru\"\n",
    "\n",
    "# rambler.ru\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@myrambler.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@autorambler.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@lenta.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@ro.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@rambler.ua)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@rambler.ru)',''))\\\n",
    "# mail.ru\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@mail.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+list.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@bk.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+internet.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+inbox.ru)',''))\\\n",
    "# gmail.com\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@gmail.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@googlemail.com)',''))\\\n",
    "# yandex.ru\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yandex.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yandex.by)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yandex.ua)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yandex.kz)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yandex.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@ya.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@narod.ru)',''))\\\n",
    "# yahoo.com\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@ymail.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@rocketmail.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yahoo.com)',''))\\\n",
    "# MICROSOFT\n",
    ".withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@hotmail.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@live.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@outlook.com)',''))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заготовки по почтам\n",
    "# находим русские буквы и эти почты(всю строку) заменяем \"UNKNOWN\"\n",
    "# пример: на входе - \"олдлод@mail.ru\" \n",
    "#         на выходе - \"UNKNOWN\"\n",
    "\n",
    "# rambler.ru\n",
    "# F.when(col(column).rlike(\"(?i)[А-Яа-яЁё]@myrambler.ru|(?i)[А-Яа-яЁё]@autorambler.ru|(?i)[А-Яа-яЁё]@lenta.ru|(?i)[А-Яа-яЁё]@ro.ru|(?i)[А-Яа-яЁё]@rambler.ua|(?i)[А-Яа-яЁё]@rambler.ru\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "# mail.ru\n",
    "# F.when(col(column).rlike(\"(?i)[А-Яа-яЁё]@mail.ru|(?i)[А-Яа-яЁё]@list.ru|(?i)[А-Яа-яЁё]@bk.ru|(?i)[А-Яа-яЁё]@internet.ru|(?i)[А-Яа-яЁё]@inbox.ru\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "# gmail.com\n",
    "# F.when(col(column).rlike(\"(?i)[А-Яа-яЁё]@gmail.com|(?i)[А-Яа-яЁё]@googlemail.com\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "# yandex.ru\n",
    "# F.when(col(column).rlike(\"(?i)[А-Яа-яЁё]@yandex.ru|(?i)[А-Яа-яЁё]@yandex.by|(?i)[А-Яа-яЁё]@yandex.ua|(?i)[А-Яа-яЁё]@yandex.kz|(?i)[А-Яа-яЁё]@yandex.com|(?i)[А-Яа-яЁё]@ya.ru|(?i)[А-Яа-яЁё]@narod.ru\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "# yahoo.com\n",
    "#F.when(col(column).rlike(\"(?i)[А-Яа-яЁё]@ymail.com|(?i)[А-Яа-яЁё]@rocketmail.com|(?i)[А-Яа-яЁё]@yahoo.com\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "# MICROSOFT\n",
    "# F.when(col(column).rlike(\"(?i)[А-Яа-яЁё]@hotmail.com|(?i)[А-Яа-яЁё]@live.com|(?i)[А-Яа-яЁё]@outlook.com\"), 'UNKNOWN').otherwise(col(column)))\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть выбор чистить почты от кирилллицы удалением букв или перевод в статус \"UNKNOWN\".  \n",
    "Но сейчас рассвет почт на кириллице, поэтому чистку применяю к почтам(доменам второго уровня),  \n",
    "у которых запрещено использования кириллицы в логине(т.е. кириллица не используется).  \n",
    "Запрос делал к каждому Российскому поставщику на начало 2022 года."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для проверки ошибок в личных почтах\n",
    "\n",
    "def email_anomalies(df,columns):\n",
    "    # Кол-во \"@\" знаков > 1\n",
    "    several_dogs = df.select(columns).filter(col(columns).rlike(\"[@]{1,}$\")).count()\n",
    "    # Кол-во пробелов в начале\n",
    "    start_clean = df.select(columns).filter(col(columns).rlike(\"^[ ]\")).count()\n",
    "    # Кол-во до двух знаков перед знаком \"@\"\n",
    "    before_dot = df.select(columns).filter(col(columns).rlike(\"^[\\w|\\W]{0,2}@\")).count()\n",
    "    # Кол-во уникальных до двух знаков перед знаком \"@\"\n",
    "    before_dot_distinct = df.select(columns).filter(col(columns).rlike(\"^[\\w|\\W]{0,2}@\")).distinct().count()\n",
    "    # Кол-во кириллицы до знаком \"@\"\n",
    "    kirillica = df.select(columns).filter(col(columns).rlike(\"[А-Яа-я]@\")).count()\n",
    "    # Кол-во уникальных кириллицы до знаком \"@\"\n",
    "    kirillica_distinct = df.select(columns).filter(col(columns).rlike(\"[А-Яа-я]@\")).distinct().count()\n",
    "    # Кол-во не допутимых с доменов mail.ru\n",
    "    yandex = df.select(columns).filter(col(columns).rlike(\"(?i)[^A-Za-z][А-Яа-я]@yandex.ru|(?i)[^A-Za-z][А-Яа-я]@ya.ru\")).count()\n",
    "    # Кол-во уникальных не допутимых с доменов mail.ru\n",
    "    yandex_unic = df.select(columns).filter(col(columns).rlike(\"(?i)[^A-Za-z][А-Яа-я]@yandex.ru|(?i)[^A-Za-z][А-Яа-я]@ya.ru\")).distinct().count()\n",
    "    # Кол-во не допутимых с доменов mail.ru\n",
    "    mail = df.select(columns).filter(col(columns).rlike(\"(?i)[^A-Za-z][А-Яа-я]@mail.ru\")).count()\n",
    "    # Кол-во уникальных не допутимых с доменов mail.ru\n",
    "    mail_unic = df.select(columns).filter(col(columns).rlike(\"(?i)[^A-Za-z][А-Яа-я]@mail.ru\")).distinct().count()\n",
    "    # Кол-во не допутимых с доменов gmail.ru\n",
    "    gmail = df.select(columns).filter(col(columns).rlike(\"(?i)[^A-Za-z][А-Яа-я]@gmail.com\")).count()\n",
    "    # Кол-во уникальных не допутимых с доменов gmail.ru\n",
    "    gmail_unic = df.select(columns).filter(col(columns).rlike(\"(?i)[^A-Za-z][А-Яа-я]@gmail.com\")).distinct().count()\n",
    "\n",
    "    print(f'Кол-во значений: {df.select(columns).count()}')\n",
    "    print(f'Кол-во значений NaN : {df.select(columns).filter(col(columns).rlike(\"^[nan]*$|^[Nan]*$\")).count()}')\n",
    "    print(f'Кол-во \"@\" знаков > 1 : {several_dogs}')\n",
    "    print(f'Кол-во пробелов в начале : {start_clean}')\n",
    "    print(f'Кол-во уникальных почт без знака \"@\" : {df.select(columns).filter(col(columns).rlike(\"^[^@]*$\")).distinct().count()}')\n",
    "    print(f'Кол-во до двух знаков(символов) перед знаком \"@\" : {before_dot}')\n",
    "    print(f'Кол-во уникальных до двух знаков перед знаком \"@\" : {before_dot_distinct}')\n",
    "    print(f'Кол-во кириллицы до знака \"@\" : {kirillica}')\n",
    "    print(f'Кол-во уникальных кириллицы до знака \"@\" : {kirillica_distinct}')\n",
    "    print(f'Кол-во не допустимых с доменом yandex.ru : {yandex}')\n",
    "    print(f'Кол-во уникальных не допустимых с доменом yandex.ru : {yandex_unic}')\n",
    "    print(f'Кол-во не допустимых с доменом mail.ru : {mail}')\n",
    "    print(f'Кол-во уникальных не допустимых с доменом mail.ru : {mail_unic}')\n",
    "    print(f'Кол-во не допустимых с доменом gmail.ru : {gmail}')\n",
    "    print(f'Кол-во уникальных не допустимых с доменом gmail.ru : {gmail_unic}')\n",
    "    print(f'Странный пробел который не пробел : {df.select(column).filter(col(column).rlike(\" \")).count()}')\n",
    "    \n",
    "email_anomalies(df_spark,col_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка сколько почт являются забанненые\n",
    "\n",
    "def check_domen(df,column,df1):\n",
    "    df = df.withColumn('domen',split(F.col(column), '@')[1])\n",
    "    df_domen = df.join(df1, df.domen==df1.domens_1,'left')\\\n",
    "        .select('domens_1').filter(col('domens_1').isNotNull()).count()\n",
    "    \n",
    "    return df_domen\n",
    "\n",
    "check_domen(df_spark,col_15,df_domens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для очистки данных личных почт\n",
    "\n",
    "def clean_email(df,column,df1):\n",
    "    df_email = df.withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"^[^@]*$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.regexp_replace(column, ' |¶|\\*|#|\\|',''))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"@[^.]+$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"[@]{2,}$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"[@]+[А-Яа-яЁёA-Za-z0-9_,.; :<>]+[@]+\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '^[!@#$%^&*()+=;:,/?\\|\\` ~\\[\\]{}^\\'\\\"<>]+',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '[!@#$%^&*()+=;:,/?\\|\\` ~\\[\\]{}^\\'\\\"<>]+$',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '(?i)[.]r$|(?i)[.]ry$','.ru'))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '(?i)маil.ru$','mail.ru'))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@myrambler.ru)|(?i)[А-Яа-яЁё]+(?=@autorambler.ru)|(?i)[А-Яа-яЁё]+(?=@lenta.ru)|(?i)[А-Яа-яЁё]+(?=@ro.ru)|(?i)[А-Яа-яЁё]+(?=@rambler.ua)|(?i)[А-Яа-яЁё]+(?=@rambler.ru)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@mail.ru)|(?i)[А-Яа-яЁё]+(?=@list.ru)|(?i)[А-Яа-яЁё]+(?=@bk.ru)|(?i)[А-Яа-яЁё]+(?=@internet.ru)|(?i)[А-Яа-яЁё]+(?=@inbox.ru)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@gmail.com)|(?i)[А-Яа-яЁё]+(?=@googlemail.com)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@yandex.ru)|(?i)[А-Яа-яЁё]+(?=@yandex.by)|(?i)[А-Яа-яЁё]+(?=@yandex.ua)|(?i)[А-Яа-яЁё]+(?=@yandex.kz)|(?i)[А-Яа-яЁё]+(?=@yandex.com)|(?i)[А-Яа-яЁё]+(?=@ya.ru)|(?i)[А-Яа-яЁё]+(?=@narod.ru)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@ymail.com)|(?i)[А-Яа-яЁё]+(?=@rocketmail.com)|(?i)[А-Яа-яЁё]+(?=@yahoo.com)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё]+(?=@hotmail.com)|(?i)[А-Яа-яЁё]+(?=@live.com)|(?i)[А-Яа-яЁё]+(?=@outlook.com)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@myrambler.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@autorambler.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@lenta.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@ro.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@rambler.ua)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@rambler.ru)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@mail.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+list.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@bk.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+internet.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+inbox.ru)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@gmail.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@googlemail.com)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yandex.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yandex.by)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yandex.ua)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yandex.kz)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yandex.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@ya.ru)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@narod.ru)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@ymail.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@rocketmail.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@yahoo.com)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, r'(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@hotmail.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@live.com)|(?i)[А-Яа-яЁё< ]+(?=[A-Za-z0-9.]+@outlook.com)',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '^[!@#$%^&*()+=;:,/?\\|\\` ~\\[\\]{}^\\'\\\"<>]+',''))\\\n",
    "        .withColumn(column, F.regexp_replace(column, '[!@#$%^&*()+=;:,/?\\|\\` ~\\[\\]{}^\\'\\\"<>]+$',''))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"[.]\\w$|[.]\\W$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"(?i)^[0-9][A-Za-zА-Яа-яЁёЁё0-9]+@yandex.by|(?i)^[0-9][A-Za-zА-Яа-яЁёЁё0-9]+@yandex.ua|(?i)^[0-9][A-Za-zА-Яа-яЁёЁё0-9]+@yandex.kz|(?i)^[0-9][A-Za-zА-Яа-яЁёЁё0-9]+@yandex.ru|(?i)^[0-9][A-Za-zА-Яа-яЁёЁё0-9]+@yandex.com|(?i)^[0-9][A-Za-zА-Яа-яЁёЁё0-9]+@ya.ru\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.when(col(column).rlike(\"^\\w{0,2}@|^\\W{0,2}@|^\\w\\W{0,2}@|^\\W\\w{0,2}@\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "        .withColumn(column, F.regexp_replace(column, 'xn----7sba5bazifhfz.xn--p1ai$','спарта-кфкс.рф'))\\\n",
    "    \n",
    "    df_email = df_email.withColumn('domen',split(F.col(column), '@')[1])\\\n",
    "        .withColumn('domen', F.regexp_replace('domen', '^[¶!@#$%^&*()+=;:,/?\\|\\`~\\[\\]{}^\\'\\\"<>]',''))\n",
    "    \n",
    "    df_email = df_email.join(df1, df_email.domen==df1.domens_1,'left')\\\n",
    "        .withColumn(column, F.when(col('domens_1').isNotNull(), 'ban_SUDIR').otherwise(col(column)))\\\n",
    "        .drop('domen', 'domens_1')\n",
    "#        .select(column).filter(col(column).rlike('[<>]')).show(100,False,True)\n",
    "     \n",
    "    return df_email\n",
    "\n",
    "clean_email(df_spark,col_15,df_domens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание функции для очистки данных личных почт\n",
    "\n",
    "def clean_email(df,column,df1):\n",
    "    # Удаляем пробел который видится как знак(два слова читаются как один)\n",
    "    .withColumn(column, F.regexp_replace(column, ' ',' '))\\\n",
    "    # Убираем почты без точек после \"@\"\n",
    "    .withColumn(column, F.when(col(column).rlike(\"@[^.]+$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "    # Убираем почты без \"@\"\n",
    "    df_email = df.withColumn(column, F.when(col(column).rlike(\"^[^@]*$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "    # Убираем все пробелы \n",
    "    .withColumn(column, F.regexp_replace(column, ' ',''))\\\n",
    "    # Убираем если больше одной \"@\"\n",
    "    .withColumn(column, F.when(col(column).rlike(\"[@]{1,}$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "    # Убираем \"nan\"\n",
    "    .withColumn(column, F.when(col(column).rlike(\"^[nan]*$|^[Nan]*$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "    # Убираем до двух знаков и символов до \"@\"\n",
    "    .withColumn(column, F.when(col(column).rlike(\"^\\w{0,2}@|^\\W{0,2}@|^\\w\\W{0,2}@|^\\W\\w{0,2}@\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "    # Убираем символы в конце почты(точки и запятые)\n",
    "    .withColumn(column, F.regexp_replace(column, '[¶.-><_]+$',''))\\\n",
    "    # Добавляем к \"r\" + \"u\" = ru\n",
    "    .withColumn(column, F.regexp_replace(column, '[.]r$','.ru'))\\\n",
    "    # Убираем домен верхнего уровня с одним символом или знаком \n",
    "    .withColumn(column, F.when(col(column).rlike(\"[.]\\w$|[.]\\W$\"), 'UNKNOWN').otherwise(col(column)))\\\n",
    "    # Заменяем Punycode на его расшифровку\n",
    "    .withColumn('Email', F.regexp_replace('Email', 'xn----7sba5bazifhfz.xn--p1ai$','спарта-кфкс.рф'))\\\n",
    "    # Заменяем маil.ru(первая буква на русском) на mail.ru\n",
    "    .withColumn(column, F.regexp_replace(column, '(?i)маil.ru$','mail.ru'))\\\n",
    "    # создаем колонку только домен второго уровня для проверки в забанненых \n",
    "    df_email = df_email.withColumn('domen',split(F.col(column), '@')[1])\n",
    "    # Джойним список с доменами второго уровня которые забаннены\n",
    "    df_email = df_email.join(df1, df_email.domen==df1.domens_1,'left')\\\n",
    "    # Убираем символы в конце почты(точки и запятые)\n",
    "    .withColumn('domen', F.regexp_replace('domen', '^[.;,/!:#-]',''))\\\n",
    "    # В колонке 'Email' убираем почты если они есть в колонке забанных\n",
    "    .withColumn(column, F.when(col('domens_1').isNotNull(), 'ban_SUDIR').otherwise(col(column)))\\\n",
    "    # Удаляем колонки которые добавили в текущей функции\n",
    "    .drop('domen', 'domens_1')\n",
    "\n",
    "    return df_email\n",
    "clean_email(df_spark,col_15,df_domens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
